{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting altair\n",
      "  Downloading altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "\u001b[K     |████████████████████████████████| 731 kB 1.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jsonschema>=3.0\n",
      "  Downloading jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "\u001b[K     |████████████████████████████████| 88 kB 167 kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging in /Users/vinoth/Desktop/Repos/Research/Transformer/env/lib/python3.9/site-packages (from altair) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/vinoth/Desktop/Repos/Research/Transformer/env/lib/python3.9/site-packages (from altair) (4.12.2)\n",
      "Collecting narwhals>=1.14.2\n",
      "  Downloading narwhals-1.15.0-py3-none-any.whl (231 kB)\n",
      "\u001b[K     |████████████████████████████████| 231 kB 3.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /Users/vinoth/Desktop/Repos/Research/Transformer/env/lib/python3.9/site-packages (from altair) (3.1.4)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/vinoth/Desktop/Repos/Research/Transformer/env/lib/python3.9/site-packages (from jsonschema>=3.0->altair) (24.2.0)\n",
      "Collecting jsonschema-specifications>=2023.03.6\n",
      "  Downloading jsonschema_specifications-2024.10.1-py3-none-any.whl (18 kB)\n",
      "Collecting rpds-py>=0.7.1\n",
      "  Downloading rpds_py-0.21.0-cp39-cp39-macosx_11_0_arm64.whl (318 kB)\n",
      "\u001b[K     |████████████████████████████████| 318 kB 3.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting referencing>=0.28.4\n",
      "  Downloading referencing-0.35.1-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/vinoth/Desktop/Repos/Research/Transformer/env/lib/python3.9/site-packages (from jinja2->altair) (3.0.2)\n",
      "Installing collected packages: rpds-py, referencing, jsonschema-specifications, narwhals, jsonschema, altair\n",
      "Successfully installed altair-5.5.0 jsonschema-4.23.0 jsonschema-specifications-2024.10.1 narwhals-1.15.0 referencing-0.35.1 rpds-py-0.21.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/Users/vinoth/Desktop/Repos/Research/Transformer/env/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install altair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from model import Transformer\n",
    "from config import get_config, get_weights_file_path\n",
    "from train import get_model, get_ds, greedy_decode\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length of source sentences: 309\n",
      "Max length of target sentences: 274\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = get_config()\n",
    "train_dataloader, val_dataloader, vocab_src, vocab_tgt = get_ds(config)\n",
    "model = get_model(config, vocab_src.get_vocab_size(), vocab_tgt.get_vocab_size()).to(device)\n",
    "\n",
    "# Load the pretrained weights\n",
    "model_filename = 'weights/tmodel_latest.pt'\n",
    "state = torch.load(model_filename)\n",
    "model.load_state_dict(state['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_next_batch():\n",
    "    # Load a sample batch from the validation set\n",
    "    batch = next(iter(val_dataloader))\n",
    "    encoder_input = batch[\"encoder_input\"].to(device)\n",
    "    encoder_mask = batch[\"encoder_mask\"].to(device)\n",
    "    decoder_input = batch[\"decoder_input\"].to(device)\n",
    "    decoder_mask = batch[\"decoder_mask\"].to(device)\n",
    "\n",
    "    encoder_input_tokens = [vocab_src.id_to_token(idx) for idx in encoder_input[0].cpu().numpy()]\n",
    "    decoder_input_tokens = [vocab_tgt.id_to_token(idx) for idx in decoder_input[0].cpu().numpy()]\n",
    "\n",
    "    # check that the batch size is 1\n",
    "    assert encoder_input.size(\n",
    "        0) == 1, \"Batch size must be 1 for validation\"\n",
    "\n",
    "    model_out = greedy_decode(\n",
    "        model, encoder_input, encoder_mask, vocab_src, vocab_tgt, config['seq_len'], device)\n",
    "    \n",
    "    return batch, encoder_input_tokens, decoder_input_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mtx2df(m, max_row, max_col, row_tokens, col_tokens):\n",
    "    return pd.DataFrame(\n",
    "        [\n",
    "            (\n",
    "                r,\n",
    "                c,\n",
    "                float(m[r, c]),\n",
    "                \"%.3d %s\" % (r, row_tokens[r] if len(row_tokens) > r else \"<blank>\"),\n",
    "                \"%.3d %s\" % (c, col_tokens[c] if len(col_tokens) > c else \"<blank>\"),\n",
    "            )\n",
    "            for r in range(m.shape[0])\n",
    "            for c in range(m.shape[1])\n",
    "            if r < max_row and c < max_col\n",
    "        ],\n",
    "        columns=[\"row\", \"column\", \"value\", \"row_token\", \"col_token\"],\n",
    "    )\n",
    "\n",
    "def get_attn_map(attn_type: str, layer: int, head: int):\n",
    "    if attn_type == \"encoder\":\n",
    "        attn = model.encoder.layers[layer].self_attention_block.attention_scores\n",
    "    elif attn_type == \"decoder\":\n",
    "        attn = model.decoder.layers[layer].self_attention_block.attention_scores\n",
    "    elif attn_type == \"encoder-decoder\":\n",
    "        attn = model.decoder.layers[layer].cross_attention_block.attention_scores\n",
    "    return attn[0, head].data\n",
    "\n",
    "def attn_map(attn_type, layer, head, row_tokens, col_tokens, max_sentence_len):\n",
    "    df = mtx2df(\n",
    "        get_attn_map(attn_type, layer, head),\n",
    "        max_sentence_len,\n",
    "        max_sentence_len,\n",
    "        row_tokens,\n",
    "        col_tokens,\n",
    "    )\n",
    "    return (\n",
    "        alt.Chart(data=df)\n",
    "        .mark_rect()\n",
    "        .encode(\n",
    "            x=alt.X(\"col_token\", axis=alt.Axis(title=\"\")),\n",
    "            y=alt.Y(\"row_token\", axis=alt.Axis(title=\"\")),\n",
    "            color=\"value\",\n",
    "            tooltip=[\"row\", \"column\", \"value\", \"row_token\", \"col_token\"],\n",
    "        )\n",
    "        #.title(f\"Layer {layer} Head {head}\")\n",
    "        .properties(height=400, width=400, title=f\"Layer {layer} Head {head}\")\n",
    "        .interactive()\n",
    "    )\n",
    "\n",
    "def get_all_attention_maps(attn_type: str, layers: list[int], heads: list[int], row_tokens: list, col_tokens, max_sentence_len: int):\n",
    "    charts = []\n",
    "    for layer in layers:\n",
    "        rowCharts = []\n",
    "        for head in heads:\n",
    "            rowCharts.append(attn_map(attn_type, layer, head, row_tokens, col_tokens, max_sentence_len))\n",
    "        charts.append(alt.hconcat(*rowCharts))\n",
    "    return alt.vconcat(*charts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: The two ships becalmed on a torpid sea, I believed to be marine phantoms.\n",
      "Target: Le due navi, in quel mare immobili, mi parevano due fantasmi marini.\n"
     ]
    }
   ],
   "source": [
    "batch, encoder_input_tokens, decoder_input_tokens = load_next_batch()\n",
    "print(f'Source: {batch[\"src_text\"][0]}')\n",
    "print(f'Target: {batch[\"tgt_text\"][0]}')\n",
    "sentence_len = encoder_input_tokens.index(\"[PAD]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MultiHeadAttentionBlock' object has no attribute 'attention_scores'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m heads \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m7\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Encoder Self-Attention\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mget_all_attention_maps\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoder\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_input_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_input_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentence_len\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 54\u001b[0m, in \u001b[0;36mget_all_attention_maps\u001b[0;34m(attn_type, layers, heads, row_tokens, col_tokens, max_sentence_len)\u001b[0m\n\u001b[1;32m     52\u001b[0m     rowCharts \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m head \u001b[38;5;129;01min\u001b[39;00m heads:\n\u001b[0;32m---> 54\u001b[0m         rowCharts\u001b[38;5;241m.\u001b[39mappend(\u001b[43mattn_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_sentence_len\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     55\u001b[0m     charts\u001b[38;5;241m.\u001b[39mappend(alt\u001b[38;5;241m.\u001b[39mhconcat(\u001b[38;5;241m*\u001b[39mrowCharts))\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m alt\u001b[38;5;241m.\u001b[39mvconcat(\u001b[38;5;241m*\u001b[39mcharts)\n",
      "Cell \u001b[0;32mIn[8], line 29\u001b[0m, in \u001b[0;36mattn_map\u001b[0;34m(attn_type, layer, head, row_tokens, col_tokens, max_sentence_len)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mattn_map\u001b[39m(attn_type, layer, head, row_tokens, col_tokens, max_sentence_len):\n\u001b[1;32m     28\u001b[0m     df \u001b[38;5;241m=\u001b[39m mtx2df(\n\u001b[0;32m---> 29\u001b[0m         \u001b[43mget_attn_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     30\u001b[0m         max_sentence_len,\n\u001b[1;32m     31\u001b[0m         max_sentence_len,\n\u001b[1;32m     32\u001b[0m         row_tokens,\n\u001b[1;32m     33\u001b[0m         col_tokens,\n\u001b[1;32m     34\u001b[0m     )\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m     36\u001b[0m         alt\u001b[38;5;241m.\u001b[39mChart(data\u001b[38;5;241m=\u001b[39mdf)\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;241m.\u001b[39mmark_rect()\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;241m.\u001b[39minteractive()\n\u001b[1;32m     47\u001b[0m     )\n",
      "Cell \u001b[0;32mIn[8], line 20\u001b[0m, in \u001b[0;36mget_attn_map\u001b[0;34m(attn_type, layer, head)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_attn_map\u001b[39m(attn_type: \u001b[38;5;28mstr\u001b[39m, layer: \u001b[38;5;28mint\u001b[39m, head: \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attn_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 20\u001b[0m         attn \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attention_block\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention_scores\u001b[49m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m attn_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     22\u001b[0m         attn \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mdecoder\u001b[38;5;241m.\u001b[39mlayers[layer]\u001b[38;5;241m.\u001b[39mself_attention_block\u001b[38;5;241m.\u001b[39mattention_scores\n",
      "File \u001b[0;32m~/Desktop/Repos/Research/Transformer/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1931\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1929\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1930\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1931\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1932\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1933\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MultiHeadAttentionBlock' object has no attribute 'attention_scores'"
     ]
    }
   ],
   "source": [
    "layers = [0, 1, 2]\n",
    "heads = [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "\n",
    "# Encoder Self-Attention\n",
    "get_all_attention_maps(\"encoder\", layers, heads, encoder_input_tokens, encoder_input_tokens, min(20, sentence_len))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MultiHeadAttentionBlock' object has no attribute 'attention_scores'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Encoder Self-Attention\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mget_all_attention_maps\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdecoder\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_input_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_input_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentence_len\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 54\u001b[0m, in \u001b[0;36mget_all_attention_maps\u001b[0;34m(attn_type, layers, heads, row_tokens, col_tokens, max_sentence_len)\u001b[0m\n\u001b[1;32m     52\u001b[0m     rowCharts \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m head \u001b[38;5;129;01min\u001b[39;00m heads:\n\u001b[0;32m---> 54\u001b[0m         rowCharts\u001b[38;5;241m.\u001b[39mappend(\u001b[43mattn_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_sentence_len\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     55\u001b[0m     charts\u001b[38;5;241m.\u001b[39mappend(alt\u001b[38;5;241m.\u001b[39mhconcat(\u001b[38;5;241m*\u001b[39mrowCharts))\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m alt\u001b[38;5;241m.\u001b[39mvconcat(\u001b[38;5;241m*\u001b[39mcharts)\n",
      "Cell \u001b[0;32mIn[8], line 29\u001b[0m, in \u001b[0;36mattn_map\u001b[0;34m(attn_type, layer, head, row_tokens, col_tokens, max_sentence_len)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mattn_map\u001b[39m(attn_type, layer, head, row_tokens, col_tokens, max_sentence_len):\n\u001b[1;32m     28\u001b[0m     df \u001b[38;5;241m=\u001b[39m mtx2df(\n\u001b[0;32m---> 29\u001b[0m         \u001b[43mget_attn_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     30\u001b[0m         max_sentence_len,\n\u001b[1;32m     31\u001b[0m         max_sentence_len,\n\u001b[1;32m     32\u001b[0m         row_tokens,\n\u001b[1;32m     33\u001b[0m         col_tokens,\n\u001b[1;32m     34\u001b[0m     )\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m     36\u001b[0m         alt\u001b[38;5;241m.\u001b[39mChart(data\u001b[38;5;241m=\u001b[39mdf)\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;241m.\u001b[39mmark_rect()\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;241m.\u001b[39minteractive()\n\u001b[1;32m     47\u001b[0m     )\n",
      "Cell \u001b[0;32mIn[8], line 22\u001b[0m, in \u001b[0;36mget_attn_map\u001b[0;34m(attn_type, layer, head)\u001b[0m\n\u001b[1;32m     20\u001b[0m     attn \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencoder\u001b[38;5;241m.\u001b[39mlayers[layer]\u001b[38;5;241m.\u001b[39mself_attention_block\u001b[38;5;241m.\u001b[39mattention_scores\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m attn_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 22\u001b[0m     attn \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attention_block\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention_scores\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m attn_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder-decoder\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     24\u001b[0m     attn \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mdecoder\u001b[38;5;241m.\u001b[39mlayers[layer]\u001b[38;5;241m.\u001b[39mcross_attention_block\u001b[38;5;241m.\u001b[39mattention_scores\n",
      "File \u001b[0;32m~/Desktop/Repos/Research/Transformer/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1931\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1929\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1930\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1931\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1932\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1933\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MultiHeadAttentionBlock' object has no attribute 'attention_scores'"
     ]
    }
   ],
   "source": [
    "# Encoder Self-Attention\n",
    "get_all_attention_maps(\"decoder\", layers, heads, decoder_input_tokens, decoder_input_tokens, min(20, sentence_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MultiHeadAttentionBlock' object has no attribute 'attention_scores'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Encoder Self-Attention\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mget_all_attention_maps\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoder-decoder\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_input_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_input_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentence_len\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 54\u001b[0m, in \u001b[0;36mget_all_attention_maps\u001b[0;34m(attn_type, layers, heads, row_tokens, col_tokens, max_sentence_len)\u001b[0m\n\u001b[1;32m     52\u001b[0m     rowCharts \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m head \u001b[38;5;129;01min\u001b[39;00m heads:\n\u001b[0;32m---> 54\u001b[0m         rowCharts\u001b[38;5;241m.\u001b[39mappend(\u001b[43mattn_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_sentence_len\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     55\u001b[0m     charts\u001b[38;5;241m.\u001b[39mappend(alt\u001b[38;5;241m.\u001b[39mhconcat(\u001b[38;5;241m*\u001b[39mrowCharts))\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m alt\u001b[38;5;241m.\u001b[39mvconcat(\u001b[38;5;241m*\u001b[39mcharts)\n",
      "Cell \u001b[0;32mIn[8], line 29\u001b[0m, in \u001b[0;36mattn_map\u001b[0;34m(attn_type, layer, head, row_tokens, col_tokens, max_sentence_len)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mattn_map\u001b[39m(attn_type, layer, head, row_tokens, col_tokens, max_sentence_len):\n\u001b[1;32m     28\u001b[0m     df \u001b[38;5;241m=\u001b[39m mtx2df(\n\u001b[0;32m---> 29\u001b[0m         \u001b[43mget_attn_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     30\u001b[0m         max_sentence_len,\n\u001b[1;32m     31\u001b[0m         max_sentence_len,\n\u001b[1;32m     32\u001b[0m         row_tokens,\n\u001b[1;32m     33\u001b[0m         col_tokens,\n\u001b[1;32m     34\u001b[0m     )\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m     36\u001b[0m         alt\u001b[38;5;241m.\u001b[39mChart(data\u001b[38;5;241m=\u001b[39mdf)\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;241m.\u001b[39mmark_rect()\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;241m.\u001b[39minteractive()\n\u001b[1;32m     47\u001b[0m     )\n",
      "Cell \u001b[0;32mIn[8], line 24\u001b[0m, in \u001b[0;36mget_attn_map\u001b[0;34m(attn_type, layer, head)\u001b[0m\n\u001b[1;32m     22\u001b[0m     attn \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mdecoder\u001b[38;5;241m.\u001b[39mlayers[layer]\u001b[38;5;241m.\u001b[39mself_attention_block\u001b[38;5;241m.\u001b[39mattention_scores\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m attn_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder-decoder\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 24\u001b[0m     attn \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_attention_block\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention_scores\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m attn[\u001b[38;5;241m0\u001b[39m, head]\u001b[38;5;241m.\u001b[39mdata\n",
      "File \u001b[0;32m~/Desktop/Repos/Research/Transformer/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1931\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1929\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1930\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1931\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1932\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1933\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MultiHeadAttentionBlock' object has no attribute 'attention_scores'"
     ]
    }
   ],
   "source": [
    "# Encoder Self-Attention\n",
    "get_all_attention_maps(\"encoder-decoder\", layers, heads, encoder_input_tokens, decoder_input_tokens, min(20, sentence_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
